#============================== ALCARECO and ALCARAW production instructions
Steps for the production using the CERN batch system (launch from lxplus):

0) Check that there are no updates in the repository:
   svn status -u
   svn update
   For indications on how to use svn, see the dedicated section below

#### ALCARAW private production
The following instructions correspond to point: 1a), 1.1a), 2a) indicated in 
Calibration/README:
https://svnweb.cern.ch/cern/wsvn/analysis/trunk/Calibration/README

For the detailed content of alcaraw format consult the Calibration/doc/alcaraw.dump file

1) Fill the alcaraw_datasets.dat with the information of the desired run range
   It is convenient to add the new line at the bottom of the file.
   For this step, in case of update of a growing dataset, please have
   a look to the "Production update" section below

2) ./scripts/prodAlcaraw.sh `parseDatasetFile.sh alcaraw_datasets.dat |grep 22Jan | grep Run2012A` --tutorial
   use the --tutorial if you are testing the machinery
   use grep commands to select the proper line from alcaraw_datasets.dat 
   the script will create the crab task and submit it
   use --createOnly or --submitOnly if needed
   see   ./scripts/prodAlcaraw.sh --help  for more informations
   
3) ./scripts/prodAlcaraw.sh `parseDatasetFile.sh alcaraw_datasets.dat |grep 22Jan | grep Run2012A` --tutorial --check
   check the job status and output

4) Commit the changes to alcaraw_datasets.dat!
   svn ci -m "message" 
#### ALCARECO private production












######### OBSOLETE INSTRUCTIONS
4a) Produce the ALCARECO: (if you have put the new line as last line)
   ./scripts/prodAlcareco.sh `parseProdSandboxOptions.sh alcaraw_datasets.dat | tail -1` --submit --scheduler lsf
   (otherwise)
   parseProdSandboxOptions.sh alcaraw_datasets.dat
   copy the output for the line you are interested in
   ./scripts/prodAlcareco.sh [PAST THE LINE] --submit --scheduler lsf

	If you are producing ALCARECO for a line added to
        alcareco_datasets.dat, just replace alcaraw_datasets.dat with
        alcareco_datasets.dat
	FOR MC: you need to add the --isMC option to the command
4b) Produce the ALCARAW: (if you have put the new line as last line)
   ./scripts/prodSandbox.sh `parseProdSandboxOptions.sh alcaraw_datasets.dat | tail -1` --submit --scheduler lsf
   (otherwise)
   parseProdSandboxOptions.sh alcaraw_datasets.dat
   copy the output for the line you are interested in
   ./scripts/prodSandbox.sh [PAST THE LINE] --submit --scheduler lsf

   To produce launching jobs on the GRID, change --scheduler lsf in --scheduler glite or --scheduler glidein

4c) To check the staus of the jobs submitted do:
   for dir in prod_alcareco/DoubleElectron-RUN2012A-May10ReReco-v1/*/; do echo $dir; ./scripts/resubmitCrab.sh -u $dir; done

   The script resubmitCrab.sh checks the exit code of each single job and it resubmits the jobs if the exit code is different from 0 except for in some cases (for particular    exit code)



5) The final output will be put:
   in the storage element indicated in the alcaraw_datasets.dat or alcareco_datasets.dat file
   in the subdir of the store/ directory indicated in the alcaraw_datasets.dat or alcareco_datasets.dat
   and following the structure indicated below:
   (STORAGE_ELEMENT)/(REMOTE_DIR)/ENERGY/(DATASETNAME)/(RUNRANGE)
	where ENERGY is 7TeV for 2011 datasets and 8TeV for 2012 datasets
        where the elements indicated in parethesys are taken from the alcaraw_datasets.dat file (or alcareco_datasets.dat)
        the REMOTE_DIR ends with sandbox/ if you are producing ALCARAW and 
        alcareco/ for ALCARECO 
    by default the output dir is the T2_CH_CERN: 
    /eos/cms/store/group/alca_ecalcalib/[alcareco/sandbox]/[7TeV/8TeV]/DATASETNAME/RUNRANGE

*** EXPERT: where REMOTE_DIR is specified by the --remote_dir option, ENERGY is 8TeV or 7TeV depending on the datasetpath, NAME is specified by the -n option and RUN_RANGE by the -r option

7) If the jobs have finished and everything is ok, commit the file
   alcaraw_datasets.dat where the line added is not commented to inform
   that the production has finished  

#============================== UPDATE ALCARECO and ALCARAW for growing dataset
In order to keep updated the ALCARECO and ALCARAW for Double and
Single electron samples follow this instructions. The production will
be in-sync with the availability of the new golden JSON file.

1) check that the new JSON is available executing the script 
   ./scripts/updateLastDataset.sh
   The output gives the following informations:

-lastRun is the last run processed
-max(run.run_number) is the last run in database
-lastWeekRun is the last run not modified since four days at least
-the last JSON

It has to be verified that the lastWeekRun is greater than the last run in JSON.
If it is not verified it is better to wait before proceeding. 
N.B: max(run.run_number) has to be always greater than the last run in JSON

Then, copy and past the last updated line from the
alcaraw_datasets.dat and change the run range accordingly

